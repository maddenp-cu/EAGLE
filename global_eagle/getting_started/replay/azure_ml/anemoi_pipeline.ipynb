{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9458bf60",
   "metadata": {},
   "source": [
    "# Welcome to the ufs2arco + Anemoi + wxvx Framework in AzureML!\n",
    "\n",
    "This notebook will guide you through the basic steps of running the full framework.\n",
    "\n",
    "1) Create your training and validation datasets with ufs2arco\n",
    "2) Submit a training job with anemoi-training\n",
    "3) Run inference with anemoi-inference\n",
    "4) Run verification with wxvx\n",
    "\n",
    "More details will be provided in each individual section.\n",
    "\n",
    "## Step 0: Configure azure settings and permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7416b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azure.ai.ml import MLClient, Input, Output, command\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    ws.subscription_id,\n",
    "    ws.resource_group,\n",
    "    ws.name,\n",
    ")\n",
    "\n",
    "# Get your workspace's default datastore (or specify another registered datastore)\n",
    "default_ds = ml_client.datastores.get_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb6d50",
   "metadata": {},
   "source": [
    "## Step 1: Create conda environments\n",
    "You only need to do this once (additionally, check if these environments were already created by someone else before running). After creation, you should be able to find them within the \"environments\" tab in AzureML. Anytime you re-run this, it will create a new version (e.g. myenv:1 would then become myenv:2). This is helpful if there is anything you wish to update in your environment (package versions, add an additional package, etc.)\n",
    "\n",
    "Environments we will create:\n",
    "1) ufs2arco for data processing\n",
    "2) anemoi for training a graph based model\n",
    "3) wxvx for post-processing and verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c14e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ufs2arco conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conf/conda/ufs2arco-conda.yaml\",\n",
    "    name=\"ufs2arco\",\n",
    "    description=\"ufs2arco environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9eb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create anemoi conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04\",\n",
    "    conda_file=\"conf/conda/anemoi-conda.yaml\",\n",
    "    name=\"anemoi\",\n",
    "    description=\"anemoi environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfc783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wxvs conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conf/conda/wxvx_conda.yaml\",\n",
    "    name=\"wxvx\",\n",
    "    description=\"wxvx environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "returned_job = ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd6d7c",
   "metadata": {},
   "source": [
    "## Step 2: Create replay dataset with ufs2arco\n",
    "This step saves a dataset that will include training and validation data together in one dataset. The zarr is saved to your default datastore. \n",
    "\n",
    "\n",
    "The default set up here assumes you have access to MPI. If you do not, here are a few changes to make to successfully create data without using MPI. Note, this will make the process take a lot longer (feel free to change your date range to something smaller if you are simply trying to run tests).\n",
    "\n",
    "- conf/data/replay.yaml: At the top of the yaml change mover to `datamover` instead of `mpidatamover`, and add a line beneath that that says `batch_size: 2`\n",
    "- conf/data/submit_ufs2arco.sh: change `mpirun --allow-run-as-root -np 8 ufs2arco replay.yaml` to simply say `ufs2arco replay.yaml`\n",
    "\n",
    "Otherwise, you should not have to change anything and should be good to go to simply run this cell!\n",
    "\n",
    "There are a few additional things to note:\n",
    "- If you have executed this cell before and the job started saving any output, due to job failure or maybe you wanted to change some configurations and test them after, the job will likely fail because a zarr already exists. Either go delete the zarr that you have, or simply rename the new zarr you wish to save by changing `output_zarr`\n",
    "- This job assumes you have access to a `Standard-D13-v2` instance. If you do not, change this to a CPU instance that you do have access to.\n",
    "- The current format of this cell also assumes that you are using version 1 (e.g. `environment=\"ufs2arco:1\"`) of your ufs2arco environment. If you have recreated this environment for whatever reason, you will need to update the version number to the most recent version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a89f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"replay/data\"\n",
    "output_zarr = \"replay.zarr\"\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{output_path}/{output_zarr}\" \n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"conf/data\",\n",
    "    command=f\"bash submit_ufs2arco.sh ${{outputs.output_blob}} {output_path} {output_zarr}\",\n",
    "    environment=\"ufs2arco:1\",\n",
    "    compute=\"Standard-D13-v2\",\n",
    "    experiment_name=\"ufs2arco\",\n",
    "    display_name=\"training_dataset\",\n",
    "    outputs={\"output_blob\": outputs},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e07b38",
   "metadata": {},
   "source": [
    "## Step 3: Submit a training job with anemoi-core\n",
    "\n",
    "After your dataset job has completed, submit this cell to complete model training. Checkpoints and plots all saved to the default datastore.\n",
    "\n",
    "A few notes to check before submission:\n",
    "- As noted in the data step, please check your environment version and compute to make sure that they match what you intend to use. \n",
    "- A `Standard-NC4as-T4-v3` is a great option for this task if it is available to you.\n",
    "\n",
    "In future work we will make a version of this that can succesfully run on a CPU. This is so users may run this with free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/data\"\n",
    "input_zarr = \"replay.zarr\"\n",
    "replay_inputs = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}/{input_zarr}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/training_output\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"conf/training\",\n",
    "    command=f\"bash submit_training.sh ${{inputs.data}} ${{outputs.output_dir}}\",\n",
    "    environment=\"anemoi:1\",\n",
    "    compute=\"Standard-NC4as-T4-v3\",\n",
    "    experiment_name=\"anemoi-training\",\n",
    "    display_name=\"anemoi-training\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\"data\": replay_inputs},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88621a",
   "metadata": {},
   "source": [
    "## Step 4: Submit inference job with anemoi-inference\n",
    "\n",
    "Run this cell after you have successfully completed trainnig. This will load the model checkpoint from the default datastore and create one 240-hr forecast. The output is saved to the default datastore.\n",
    "\n",
    "A few notes to check before submission:\n",
    "- As always, check your compute and environment. \n",
    "- In the first line (`input_path`), you will need to go to your default datastore and find the run_id (`3f476fd7-65ca-4d98-b3d5-b622d88a0d7d`) that is unique to you. This ID differs with each model run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/training-output/checkpoint/3f476fd7-65ca-4d98-b3d5-b622d88a0d7d\"\n",
    "input_ckpt = \"inference-last.ckpt\"\n",
    "ckpt_input = Input(\n",
    "    type=\"uri_file\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}/{input_ckpt}\",\n",
    ")\n",
    "\n",
    "input_path = \"replay/data\"\n",
    "zarr_input = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/replay/inference\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"conf/inference\",\n",
    "    command=f\"python inference.py ${{inputs.ckpt}} ${{inputs.zarr}} ${{outputs.output_dir}}\",\n",
    "    environment=\"anemoi:1\",\n",
    "    compute=\"Standard-NC4as-T4-v3\",\n",
    "    experiment_name=\"anemoi-inference\",\n",
    "    display_name=\"anemoi-inference\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\n",
    "        \"ckpt\": ckpt_input,\n",
    "        \"zarr\": zarr_input,\n",
    "    },\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854cbfd",
   "metadata": {},
   "source": [
    "## Step 5: Submit verification job with wxvx\n",
    "\n",
    "Load inference, post-process the output so that will work with wxvx, and run verification against the GFS for a handful of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f55c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/inference\"\n",
    "zarr_input = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/replay/verification\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"conf/verification\",\n",
    "    command=f\"bash submit_wxvx.sh ${{inputs.zarr}} ${{outputs.output_dir}}\",\n",
    "    environment=\"wxvx:1\",\n",
    "    compute=\"Standard-D13-v2\",\n",
    "    experiment_name=\"wxvx\",\n",
    "    display_name=\"wxvx\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\"zarr\": zarr_input},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
